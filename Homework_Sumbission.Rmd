---
title: "Homework Sumbission"
output:
  html_document: default
  word_document: default
  pdf_document: default
date: "2024-11-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #this makes the document default to have echo = TRUE
options(tinytex.verbose = TRUE)
```

*The following is a template .rmd RMarkdown file for you to use for your homework submission.*

*Please Knit your .rmd to a PDF format or HTML and submit that with no identifiers like your name.*

*To create a PDF, first install tinytex and load the package. Then press the Knit arrow and select "Knit to PDF".*

<br>

## QUESTION 01: Data Visualisation for Science Communication

*Create a figure using the Palmer Penguin dataset that is correct but badly communicates the data. **Do not make a boxplot**.*

*Use the following references to guide you:*

-   [*https://www.nature.com/articles/533452a*](https://www.nature.com/articles/533452a){.uri}
-   [*https://elifesciences.org/articles/16800*](https://elifesciences.org/articles/16800){.uri}

*Note: Focus on visual elements rather than writing misleading text on it.*

### a) Provide your figure here:

```{r bad figure, echo=FALSE, message=FALSE, warning=FALSE, results="hide"}

# Make sure your figure is visible after you knit it. 

library(here)
library(tidyverse)
library(janitor)
library(dplyr)
library(knitr) 
library(rmarkdown) 
library(here) 
library(tidyverse) 
library(janitor)
library(ggplot2)
library(tinytex)

source(here("functions", "cleaning.r"))

penguins_untidy <- read_csv(here("data", "penguins_raw.csv"))

penguins_tidy <- penguins_untidy %>%
  cleaning_columns() %>% #automatically snake case
  shorten_species() %>%
  remove_empty_columns_rows() %>% 
  remove_NA() 


ggplot(data = penguins_tidy, aes(x = date_egg, y = body_mass_g)) +
  stat_smooth(method = "lm", se = FALSE, color = "darkred", 
              geom = "line", 
              linewidth = 1,  # Increase line thickness
              arrow = arrow(length = unit(0.2, "cm"), ends = "last", type = "closed")) +
  geom_point(color = "darkred", alpha = 0.2) +
  coord_fixed(ratio = 2) +
  theme_bw() +
  theme(axis.text.y = element_blank()) +
  scale_y_continuous() +
  coord_cartesian(ylim = c(4150, 4300)) +

    scale_x_date(
    breaks = as.Date(c("2008-01-01", "2008-07-01", "2009-01-01", "2009-07-01", "2010-01-01")),
    labels = c(expression(bold("2008-01")), "2008-07", "2009-01", "2009-07", "2010-01")
  ) +
  labs(
    title = "Palmer Penguin Body Mass over Time",
    x = "Time since Chef Smith's Arrival",
    y = "Body Mass (g)"
  )

#^fix X-axis cut-off >55 words too long
```

<br>

### b) Write about how your design choices mislead the reader about the underlying data (100-300 words).

Imagine a scenario where I am in an argument with Chef Smith, who was hired at the start of 2008 to my Antarctic field station workplace. I devise a plan to get them fired by convincing the public that their food waste is causing an obesity epidemic around the Palmer Station, Antarctica LTER. Taking to twitter, I share the above graph.

Points of deception:

-   I have started the graph from where the linear relationship begins, rather than 0 or another appropriate point. This exaggerates the steepness of the linear relationship, which would look almost negligible if seen as it should be.

-   I am only using the species Gentoo, but extrapolating to all Palmer Penguin's in the title. In fact, Adelie Penguins have gotten smaller since Chef Smith's arrival. (N.B. I am taking the graph title and axis labels to be "visual elements").

-   I have elected to make the line red, a colour commonly associated with negatives. This aims to distract from the fact that weight increase isn't intrinsically negative.

-   I have made the line an arrow. This aims at convincing the reader of a continued projected increase should Chef Smith remain employed.

-   Rather than labeling with the objective "Date", I have drawn attention to how time relates to my intended point.

-   I have used the code "coord_fixed(ratio = 10)" which stretches the graph vertically and hugely exaggerates the steepness of the line.

-   I have made the individual label 2008-01 bold. I did this while ensuring the axes remain the same as when they are entered in a repeatable manner, so it remains technically "correct". The intended effect is to again call attention to the false association between Chef Smith's arrival and increased penguin body mass.

-   I used scale_y_continuous() along with coord_cartesian(ylim = c(x1, x2)). This enabled me to manipulate the y axis, while coord_cartesian() ensured that the "zoom effect" excludes the data points from the graph but not the lm(). This circumvents an issue where it looks too obviously fabricated without any data visible.

<br>

------------------------------------------------------------------------

## QUESTION 2: Data Analysis Pipeline

------------------------------------------------------------------------

### Introduction

#### What is the data?

The data features various pieces of information gathered on three species of Penguins around the Palmer Station, Antarctica. Collected variables include geographical data, various morphological characteristics, and details on reproductive success.

<br>

#### Load libraries

I start by loading the libraries we will be using. To protect the environment, I will be using `renv()`. This is a package that ensures the packages we use have a record of which version was being used at the time we write our code. This prevents subsequent updates to packages from affecting our code's functionality.

I considered loading packages in a separate file and importing them with `source()`; however, am opting not to as, despite keeping the code marginally cleaner, readers are forced to open an additional file and reduces the level of self-containment from the .Rmd file. Users can then use `renv::status()` to ensure the packages are correctly loaded in a consistent state.

```{r Libraries, echo=TRUE, message=FALSE, warning=FALSE}
# Make sure your code prints.

library(renv) 
library(knitr) 
library(rmarkdown) 
library(here) 
library(tidyverse) 
library(janitor)
library(tinytex)
library(svglite)
library(ragg)
library(car)
library(MASS)
library(gridExtra)
library(grid)

renv::status()
```

<br>

#### Load data

On to the data itself. This was downloaded and placed in the file `data`. We could load the data from the `palmerpenguins` package. More often in reality we will be loading data from files rather than R packages. Hence, I push the file to my GitHub Repository. If someone downloads the repository, this should be functional and more realistic.

I can then visualize the data with the `read_csv()` function, contained in tidyverse and producing a "tibble". Tibbles are a "modern take on data frames" (R Core Team, 2024). The `here()` function avoids privacy concerns by sidestepping entering file directories and improves operating system cross-compatibility.

```{r Data Exploration}
penguins_raw <- suppressMessages(read_csv(here("data", "penguins_raw.csv"), show_col_types = FALSE))

head(penguins_raw)
```

<br>

#### *Cleaning data*

Next in the pipeline, we can look specifically at the column names.

```{r}
colnames(penguins_raw)
```

<br>

It is apparent from the mixture of styles (e.g. camel case and sentence case) and abundance of error causing characters (e.g. spaces, brackets, and slashes) that we should clean our dataset. Here, it is important to resist the urge to edit the raw data, as this ruins reproducibility. Instead we should make a new cleaned dataset.

```{r data cleaning}
source(here("functions", "cleaning.r"))

penguins_clean <- penguins_raw %>%
  cleaning_columns() %>% #automatically snake case
  shorten_species() %>%
  remove_empty_columns_rows() %>% 
  remove_NA() 

colnames(penguins_clean)

```

<br>

The above code begins by sourcing a file named `cleaning.r` from within our directory. It uses Dr France's functions for cleaning the data, which itself uses generic cleaning functions from the "janitor" package. By using `source()` and a separate file, we streamline our work by ensuring any functions which may be used multiple times in the project only need to be edited in one place. The code also makes use of a "pipe" (`%>%`), here styled as part of the `tidyverse` package. It is essentially equivalent to the instruction "and then".

<br>

#### *Create an Exploratory Figure*

I'm interested in whether there is any relationship between the categorical variable "clutch_completion" and "body_mass_g". More specifically, I am interested to look at whether body mass as an explanatory variable has any noticable influence on fitness, which I will use clutch completion as a proxy for. I expect this to naturally vary between species and sex, so want to control for those factors. I will assume that time and geographical factors are independent.

Next in my data pipeline, I will subset the data into these factors of interest with the `select()` function

```{r data subset}
body_mass_clutch <- penguins_clean %>%
  dplyr::select(species, body_mass_g, sex, clutch_completion) #specify package as MASS has conflict

```

<br>

Rather than using a boxplot, I use a violin plot. This is another useful exploratory graph technique with a bigger focus on data distribution compared to a boxplot's focus on summary statistics.

```{r explanatory figure}
#combine data columns into one for colour coding the graph. Make new dataset to avoid overwriting

body_mass_clutch_updated <- transform(body_mass_clutch, 
                                      species_clutch = paste(species, clutch_completion, sep = "_"))
  
  species_shades <- c(
    "Adelie_No" = "#006d4c",  
    "Adelie_Yes" = "#66c2a4", 
    "Chinstrap_No" = "#ff8c66",  
    "Chinstrap_Yes" = "#ffb399", 
    "Gentoo_No" = "#c653c6",  
    "Gentoo_Yes" = "#ecc6ec"
  )
  
  
violin_plot <- ggplot(body_mass_clutch_updated, aes(x = clutch_completion, y = body_mass_g, fill = species_clutch)) +
    geom_violin() +
    stat_summary(fun = mean, geom = "crossbar", width = 0.9, linewidth = 0.2, color = "black") + # add mean lines
    facet_wrap(~species) +
    theme_minimal() +
    scale_fill_manual(values = species_shades) + # use custom color scheme
    labs(title = "Body Mass by Clutch Completion for Each Species",
         x = "Clutch Completion",
         y = "Body Mass (g)",
         fill = "Species and Clutch Completion") + 
    theme_bw() +
    theme(
      legend.position = "none",
      strip.text = element_text(size = 12),
      ) +
  geom_jitter(
        aes(color = ),
        alpha = 0.1,
        show.legend = FALSE, 
        position = position_jitter(width = 0.2, seed = 0)) # seed number to add reproducibility

print(violin_plot)

```

I considered adding the plotting code to a function file; however, since I am only asked to do this plot decided it is simpler to display the code in the document.

I have done a number of steps related to communicating the data in a clear way. I begin by creating a new dataset (avoiding overwriting) with a new column that contains information on both the species and clutch completion. This allows me to colour plots individually down the line.

I then code the plot itself. I begin by plotting the violin plot while faceting for species, a variable I see as likely important for weight independently and this is supported by the graph.

As an exploratory figure, I employ `geom_jitter()` to show the raw data along with setting a seed for reproducibility.

`stat_summary` is used to add the mean, which I feel is a helpful visual comparison.

We can see from the figure that Gentoo penguins tend to be much bigger. And that in all three species the majority of penguins complete a clutch, seen from the greater number of data points in each "Yes" position. The means do not appear to be visually very different.

<br>

#### *Save the exploratory figure.*

```{r saving explanatory figure}
save_plot_svg <- function(plot, 
                                  filename, size, scaling){
    size_inches = size/2.54
    svglite(filename, width   = size_inches, 
                      height  = size_inches, 
                      scaling = scaling)
    print(plot)
    dev.off()
}

save_plot_svg(violin_plot, 
                       here("figures", "violin_plot.svg"), 
                       size = 19, scaling = 1.5)
```

I used a function covered in the computer class. I then used the function to save the plot, setting the size with viewing the graph full-screen on a computer in mind.

<br>

### Hypotheses

$\text{H}_0 :$ There is no significant difference in the probability of clutch completion according to body mass.

$\text{H}_{a1} :$ Penguins with greater body mass have significantly higher probability of clutch completions.

$\text{H}_{a2} :$ Penguins with greater body mass have significantly probability of lower clutch completions.

<br>

### Statistical Methods

I model the data using a binomial logistic regression with clutch_completion as the response variable.

$$\\ln\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_n X_n$$

I include the variables sex and species as variables I consider potentially influencing clutch completion. Controlling for these potential influences could improve the power of the model.

```{r Statistics}
#convert completion into 1 = yes, 0 = no.
body_mass_clutch_updated$clutch_completion_binary <- ifelse(body_mass_clutch$clutch_completion == "Yes", 1, 0) # new column to allow binomial logistic model 

logistic_regression_model <- glm(clutch_completion_binary ~ body_mass_g + sex + species, 
             family = binomial(link = "logit"), 
             data = body_mass_clutch_updated)
summary(logistic_regression_model)



```

Above, I create a new column in the dataset `body_mass_clutch_updated` with values `Yes` and `No` converted to `1` and `0`, respectively. This allows the binomial logistic regression to run, which uses `glm`. A linear model uses the a direct link function, to make predictions on the response scale. The binomial logistic regression uses the `logit` link function, which converts predictions to the probabilistic log-odds scale. To discuss the results, it is common practice to exponentiate the coefficients in order to interpret them as odds-ratios.

<br>

#### *Checking model assumptions*

I start with with multicollinearity. Sexes and species can tend to be collinear with size. If this is the case, it could make our model results appear stronger than they should through a form of double counting.

```{r}
vif(logistic_regression_model)
```

The variance inflation factors (`vif()`) indicate moderate multicollinearity between body mass and the other two factors. It is not so extreme as to neccessitate excluding any variables from the model. Instead we should be cautious to consider multicollinearity's potential bias when interpreting the model.

<br>

##### Over-fitting

To check for over-fitting, I will use a stepwise test to remove non-significant factors based on AIC criteria. As this model contains fairly few factors with a reasonable number of samples, this is unlikely to be a major concern. It is worth putting in our pipeline process, however, as a good habit.

```{r show-code-hide-output, results = "hide"}
stepwise_model <- stepAIC(logistic_regression_model, direction = "both")

```

```{r}
summary(stepwise_model)
```

In both the selected model and the full model, the comparison between Adelie and Gentoo clutch completion success is the only statistically significant factor for predicting clutch. The difference in AIC scores is minimal, indicating either model can be chosen.

<br>

##### Independence

To check for independence, it can often be useful to plot collection against time.

```{r}
plot_independence <- function(data, time_col, value_col, group_col = NULL) {
    # Convert column names to symbols
  time_sym <- rlang::sym(time_col)
  value_sym <- rlang::sym(value_col)
  
set.seed(0)
  
p <- ggplot(data, aes(x = !!time_sym, y = !!value_sym)) +
    geom_point(alpha = 0.6) +
    labs(
      x = "Time",
      y = "Observed Value",
      title = "Check for Independence Over Time") +
    theme_minimal()
    return(p)
}

plot <- plot_independence(
  data = penguins_clean,
  time_col = "date_egg",
  value_col = "body_mass_g"
)

print(plot)
```

<br>

##### Linear relationship

Finally, we should check the assumption of a linear relationship between continuous explanatory variables and the logit of the response variable with a Box-Tidwell Test.

```{r}


boxTidwell(clutch_completion_binary ~ body_mass_g, data = body_mass_clutch_updated)
```

The p-value indicates that we fail to reject the null hypothesis, which is that the relationship is linear. In other words, the assumption is not violated.

<br>

### Results & Discussion

"*A results figure demonstrates the stats method chosen, and includes the results of the stats test or model."*

#### Results

```{r Plotting Results, message=FALSE}

# Make sure your code prints. 

# extract typical statistics used to interpret model
coefficients <- summary(logistic_regression_model)$coefficients #extract coefficients 
odds_ratios <- exp(coefficients[, "Estimate"])  #find odds-ratios by taking exponential
conf_int <- exp(confint(logistic_regression_model))  # confidence intervals for odds ratios

results_df <- data.frame(
    Name = c(
    "Intercept",
    "Body Mass (grams)",
    "Male (vs Female)",
    "Chinstrap (vs Adelie)",
    "Gentoo (vs Adelie)"
  ),
  Odds_Ratio = odds_ratios,
  CI_Lower = conf_int[, 1],
  CI_Upper = conf_int[, 2],
  p_value = coefficients[, "Pr(>|z|)"],
  stringsAsFactors = FALSE
)

results_df$Odds_Ratio <- formatC(results_df$Odds_Ratio, format = "f", digits = 3)
results_df$CI_Lower <- formatC(results_df$CI_Lower, format = "f", digits = 3)
results_df$CI_Upper <- formatC(results_df$CI_Upper, format = "f", digits = 3)
results_df$p_value <- formatC(results_df$p_value, format = "f", digits = 3)

results_df$Significance <- cut(as.numeric(results_df$p_value),
                               breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                               labels = c("***", "**", "*", ".", " "))

# remove non-human readable row names
rownames(results_df) <- NULL


# view data frame as tibble in .Rmd
results_df

```

The above code begins by extracting the relevant estimates, covered in [Statistical Methods]. I then create a data-frame which contains the extracted estimates along with human readable row names. I reduce the number of significant figures to improve the readability. Finally, I add a standard code to show the significance of any p_values. Finally, I hide the original row names and create the tibble seen above.

<br>

##### Saving table

Next I will make a new function to save the table. This requires the additional package `gridExtra`.

```{r saving table as SVG}


save_table_svg <- function(table, filename, size, scaling, title = NULL, vjust = NULL) {
    size_inches = size / 2.54  # Convert cm to inches
    svglite(filename, width = size_inches, height = size_inches, scaling = scaling)
    
    if (!is.null(title)) {
        # Create a title grob with the calculated vjust
        title_grob <- textGrob(
            title, 
            gp = gpar(fontsize = 14, fontface = "bold"),
            vjust = vjust
        )
        
        # arrange title and table heights in the output
        grid.arrange(title_grob, tableGrob(table), heights = c(1, 10))
    } else {
        # avoid errors if no title
        grid.table(table)
    }
    
    dev.off()  # close device
}


save_table_svg(
    results_df,
    here("figures", "table.svg"),
    size = 19, 
    scaling = 1,
    title = "Results Table of Binomial Logistic Model",
    vjust = 18  # custom vertical for title independent of table
)


```

![](figures/table.svg)

Here is the table, inserted as an image and available on GitHub.

<br>

#### Discussion

The results show that there is no statistically significant effect of body mass on clutch completion. The probability our ratio of successes to failures occurred by random chance is 0.0940.

What is perhaps of more interest in the case of Body Mass in the table is the confidence intervals. They are extremely narrow around an odds-ratio = 1. This indicates that even if our result were significant statistically, the biological significance would nevertheless be negligable, as an odds-ratio of 1 is indicative of their being no difference in the probability. So if our result is significant, but significantly equal to the ratio being 1.001, this is such a minor improvement of clutch success that it should nevertheless be ignored.

I included the variable sex as if different sexes have to compete or if multiple mating occurs, this could influence the sexes' chances of completing a clutch. The model does not indicate any consistent difference between the sexes when looking at sex interspecifically. The general trend is that being male lowers the probability of clutch completion, however this is not statistically significant. Here it has a wide confidence interval which intersects 1. A separate analysis may want to look for species-sex interactions, as you could imagine such behaviours being species specific.

For species, we can imagine different ecologies contributing to different clutch survivals. Perhaps the Chinstrap is able to dominate Adelie for a preferable niche if they coexist. Alternatively, Chinstrap penguins could be more k-selected than Adelie, although the larger body size of Gentoo penguins while simultaneously not being more liekly to have a successful clutch is a reason to doubt this.

The model met most of its assumptions. The independence would have been better if sampling had not taken place in such short time-windows. We could imagine a scenario where different life-histories mean Chinstrap clutches are more firmly established as complete at a later point than December when these species are consistently being sampled, for example if offspring morality is far higher some time after clutch completion but before adulthood.

The moderate multicollinearity can be ignored as the step-wise model with only the Chinstrap shows essentially the same results as when the other factors are included.

<br>

### Conclusion

Overall, we have been able to create a valid model which supports our null hypothesis that there is no significant difference in the probability of clutch completion according to body mass. Even if the sample size was increased and showed a statistically significant effect, it's biological relevance is still likely completely negligible. This result is perhaps slightly surprising since we often associate larger body mass with a better fitness. Further study may wish to investigate why this is not the case for these species of penguin.

<br>

------------------------------------------------------------------------

## QUESTION 3: Open Science

### a) GitHub

*Upload your RProject you created for **Question 2** and any files and subfolders used to GitHub. Do not include any identifiers such as your name. Make sure your GitHub repo is public.*

*GitHub link: <https://github.com/Anonymous-Exam-User/Palmer_Penguin_GitHub>*

*You will be marked on your repo organisation and readability.*

### b) Share your repo with a partner, download, and try to run their data pipeline.

*Partner's GitHub link: <https://github.com/lemontea63/reproducible_figures_assignment>*

*You **must** provide this so I can verify there is no plagiarism between you and your partner.*

### c) Reflect on your experience running their code. (300-500 words)

-   *What elements of your partner's code helped you to understand and run their data pipeline?*

My partner has extensively annotated their code, explaining what each line does in most cases. This helps understanding. By following the template, running their data follows a logical sequence. YAML headers also help understand what each chunk is for.

-   *Did it run? Did you need to fix anything?*

Broadly, yes the code ran. I first encountered an issue with the first library chunk, running `renv::restore()`, which should install the correct packages from the lockfile; however, I noticed some discrepancies. I got around this by just installing the most recent required packages with `renv::install()` . This works for now; however, isn't ideal for long-term reproducibility.

`renv::status()` revealed that "the lockfile was generated with R 4.4.1, but you're using R 4.2.2". This didn't seem to cause any issues and, if it did, it would fall on me to align the versions.

I move on to data preparation, which immediately gives an error:

```         
> head(penguins_data_raw)
```

```         
-Error in tempfile(pattern = "_rs_rdf_", tmpdir = outputFolder, fileext = ".rdf") : 
```

```         
-temporary name too long
```

I circumvented this by re-exracting the repo to my Documents file, instead of a deeply nested OneDrive file. This fixed the issue.

When trying to run the data preparation chunk (line 134), it would not run when using the Run Current Chunk button. I was getting errors around text being part of the chunk. It was solved by adding a line break between the above section and the code chunk.

-   *What suggestions would you make for improving their code to make it more understandable or reproducible, and why?*

I find the in-code descriptions more difficult to read than the text sections. Personally, I think breaking the coding chunks into smaller segments and moving annotations to a text format would make the code more understandable. Additionally, where direct code annotations are preferable, such as for a minor annotation, I think the ease of understanding is improved if annotations immediately proceed the code, rather than all being found at the start of the coding sequence.

I think the code would be more readable if indents were smaller in some cases, such as with ggplot. The large indents followed by lines that over-run the line make following the logic more challenging to me.

When initially cleaning data, `na.omit()` is not included which causes some warning messages. It is used later when subsetting the data.

In the statistics chunk (line 337), the chunk produces two plated plots of Q-Q and Residuals vs Fitted. These seem almost identical and the cause for small difference between them is not obvious from the code. This does not make the user confident in the graph's reproducibility.

References are difficult to read in the bibliography and might have benefited from using Quarto's referencing capabilities.

-   *If you needed to alter your partner's figure using their code, do you think that would be easy or difficult, and why?*

I think the biggest obstacle to altering my partner's code would be the overall readability. Editing small, easily visible components like a title in a graph or colour would likely be easy. However, higher level, conceptual changes would likely be more difficult as a consequence of the formatting.

### d) Reflect on your own code based on your experience with your partner's code and their review of yours. (300-500 words)

-   *What improvements did they suggest, and do you agree?*

-   *What did you learn about writing code for other people?*
